{"cells":[{"cell_type":"code","execution_count":1,"source":["import glob\n","import random\n","import os\n","import os.path as osp\n","\n","import cv2\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torch\n","import torch.nn.functional as F\n","from torchvision.ops import nms\n","\n","\n","def mkdir_if_missing(dir):\n","    os.makedirs(dir, exist_ok=True)\n","\n","\n","def float3(x):  # format floats to 3 decimals\n","    return float(format(x, '.3f'))\n","\n","\n","def init_seeds(seed=0):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","\n","\n","def load_classes(path):\n","    \"\"\"\n","    Loads class labels at 'path'\n","    \"\"\"\n","    fp = open(path, 'r')\n","    names = fp.read().split('\\n')\n","    return list(filter(None, names))  # filter removes empty strings (such as last line)\n","\n","\n","def model_info(model):  \n","    \"\"\"\n","    Prints out a line-by-line description of a PyTorch model ending with a summary.\n","    \"\"\"\n","    n_p = sum(x.numel() for x in model.parameters())  # number parameters\n","    n_g = sum(x.numel() for x in model.parameters() if x.requires_grad)  # number gradients\n","    print('\\n%5s %50s %9s %12s %20s %12s %12s' % ('layer', 'name', 'gradient', 'parameters', 'shape', 'mu', 'sigma'))\n","    for i, (name, p) in enumerate(model.named_parameters()):\n","        name = name.replace('module_list.', '')\n","        print('%5g %50s %9s %12g %20s %12.3g %12.3g' % (\n","            i, name, p.requires_grad, p.numel(), list(p.shape), p.mean(), p.std()))\n","    print('Model Summary: %g layers, %g parameters, %g gradients\\n' % (i + 1, n_p, n_g))\n","\n","\n","\n","def plot_one_box(x, img, color=None, label=None, line_thickness=None):\n","    \"\"\"\n","    Plots one bounding box on image img.\n","    \"\"\"\n","    tl = line_thickness or round(0.0004 * max(img.shape[0:2])) + 1  # line thickness\n","    color = color or [random.randint(0, 255) for _ in range(3)]\n","    c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\n","    cv2.rectangle(img, c1, c2, color, thickness=tl)\n","    if label:\n","        tf = max(tl - 1, 1)  # font thickness\n","        t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]\n","        c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n","        cv2.rectangle(img, c1, c2, color, -1)  # filled\n","        cv2.putText(img, label, (c1[0], c1[1] - 2), 0, tl / 3, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)\n","\n","\n","def weights_init_normal(m):\n","    classname = m.__class__.__name__\n","    if classname.find('Conv') != -1:\n","        torch.nn.init.normal_(m.weight.data, 0.0, 0.03)\n","    elif classname.find('BatchNorm2d') != -1:\n","        torch.nn.init.normal_(m.weight.data, 1.0, 0.03)\n","        torch.nn.init.constant_(m.bias.data, 0.0)\n","\n","\n","def xyxy2xywh(x):\n","    # Convert bounding box format from [x1, y1, x2, y2] to [x, y, w, h]\n","    # x, y are coordinates of center \n","    # (x1, y1) and (x2, y2) are coordinates of bottom left and top right respectively. \n","    y = torch.zeros_like(x) if x.dtype is torch.float32 else np.zeros_like(x)\n","    y[:, 0] = (x[:, 0] + x[:, 2]) / 2  # x center\n","    y[:, 1] = (x[:, 1] + x[:, 3]) / 2  # y center\n","    y[:, 2] = x[:, 2] - x[:, 0]  # width\n","    y[:, 3] = x[:, 3] - x[:, 1]  # height\n","    return y\n","\n","\n","def xywh2xyxy(x):\n","    # Convert bounding box format from [x, y, w, h] to [x1, y1, x2, y2]\n","    # x, y are coordinates of center \n","    # (x1, y1) and (x2, y2) are coordinates of bottom left and top right respectively. \n","    y = torch.zeros_like(x) if x.dtype is torch.float32 else np.zeros_like(x)\n","    y[:, 0] = (x[:, 0] - x[:, 2] / 2)  # Bottom left x\n","    y[:, 1] = (x[:, 1] - x[:, 3] / 2)  # Bottom left y\n","    y[:, 2] = (x[:, 0] + x[:, 2] / 2)  # Top right x\n","    y[:, 3] = (x[:, 1] + x[:, 3] / 2)  # Top right y\n","    return y\n","\n","\n","def scale_coords(img_size, coords, img0_shape):\n","    # Rescale x1, y1, x2, y2 from 416 to image size\n","    gain_w = float(img_size[0]) / img0_shape[1]  # gain  = old / new\n","    gain_h = float(img_size[1]) / img0_shape[0]\n","    gain = min(gain_w, gain_h)\n","    pad_x = (img_size[0] - img0_shape[1] * gain) / 2  # width padding\n","    pad_y = (img_size[1] - img0_shape[0] * gain) / 2  # height padding\n","    coords[:, [0, 2]] -= pad_x\n","    coords[:, [1, 3]] -= pad_y\n","    coords[:, 0:4] /= gain\n","    coords[:, :4] = torch.clamp(coords[:, :4], min=0)\n","    return coords\n","\n","\n","def ap_per_class(tp, conf, pred_cls, target_cls):\n","    \"\"\" Computes the average precision, given the recall and precision curves.\n","    Method originally from https://github.com/rafaelpadilla/Object-Detection-Metrics.\n","    # Arguments\n","        tp:    True positives (list).\n","        conf:  Objectness value from 0-1 (list).\n","        pred_cls: Predicted object classes (list).\n","        target_cls: True object classes (list).\n","    # Returns\n","        The average precision as computed in py-faster-rcnn.\n","    \"\"\"\n","\n","    # lists/pytorch to numpy\n","    tp, conf, pred_cls, target_cls = np.array(tp), np.array(conf), np.array(pred_cls), np.array(target_cls)\n","\n","    # Sort by objectness\n","    i = np.argsort(-conf)\n","    tp, conf, pred_cls = tp[i], conf[i], pred_cls[i]\n","\n","    # Find unique classes\n","    unique_classes = np.unique(np.concatenate((pred_cls, target_cls), 0))\n","\n","    # Create Precision-Recall curve and compute AP for each class\n","    ap, p, r = [], [], []\n","    for c in unique_classes:\n","        i = pred_cls == c\n","        n_gt = sum(target_cls == c)  # Number of ground truth objects\n","        n_p = sum(i)  # Number of predicted objects\n","\n","        if (n_p == 0) and (n_gt == 0):\n","            continue\n","        elif (n_p == 0) or (n_gt == 0):\n","            ap.append(0)\n","            r.append(0)\n","            p.append(0)\n","        else:\n","            # Accumulate FPs and TPs\n","            fpc = np.cumsum(1 - tp[i])\n","            tpc = np.cumsum(tp[i])\n","\n","            # Recall\n","            recall_curve = tpc / (n_gt + 1e-16)\n","            r.append(tpc[-1] / (n_gt + 1e-16))\n","\n","            # Precision\n","            precision_curve = tpc / (tpc + fpc)\n","            p.append(tpc[-1] / (tpc[-1] + fpc[-1]))\n","\n","            # AP from recall-precision curve\n","            ap.append(compute_ap(recall_curve, precision_curve))\n","\n","    return np.array(ap), unique_classes.astype('int32'), np.array(r), np.array(p)\n","\n","\n","def compute_ap(recall, precision):\n","    \"\"\" Computes the average precision, given the recall and precision curves.\n","    Code originally from https://github.com/rbgirshick/py-faster-rcnn.\n","    # Arguments\n","        recall:    The recall curve (list).\n","        precision: The precision curve (list).\n","    # Returns\n","        The average precision as computed in py-faster-rcnn.\n","    \"\"\"\n","    # correct AP calculation\n","    # first append sentinel values at the end\n","\n","    mrec = np.concatenate(([0.], recall, [1.]))\n","    mpre = np.concatenate(([0.], precision, [0.]))\n","\n","    # compute the precision envelope\n","    for i in range(mpre.size - 1, 0, -1):\n","        mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n","\n","    # to calculate area under PR curve, look for points\n","    # where X axis (recall) changes value\n","    i = np.where(mrec[1:] != mrec[:-1])[0]\n","\n","    # and sum (\\Delta recall) * prec\n","    ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n","    return ap\n","\n","\n","def bbox_iou(box1, box2, x1y1x2y2=False):\n","    \"\"\"\n","    Returns the IoU of two bounding boxes\n","    \"\"\"\n","    N, M = len(box1), len(box2)\n","    if x1y1x2y2:\n","        # Get the coordinates of bounding boxes\n","        b1_x1, b1_y1, b1_x2, b1_y2 = box1[:, 0], box1[:, 1], box1[:, 2], box1[:, 3]\n","        b2_x1, b2_y1, b2_x2, b2_y2 = box2[:, 0], box2[:, 1], box2[:, 2], box2[:, 3]\n","    else:\n","        # Transform from center and width to exact coordinates\n","        b1_x1, b1_x2 = box1[:, 0] - box1[:, 2] / 2, box1[:, 0] + box1[:, 2] / 2\n","        b1_y1, b1_y2 = box1[:, 1] - box1[:, 3] / 2, box1[:, 1] + box1[:, 3] / 2\n","        b2_x1, b2_x2 = box2[:, 0] - box2[:, 2] / 2, box2[:, 0] + box2[:, 2] / 2\n","        b2_y1, b2_y2 = box2[:, 1] - box2[:, 3] / 2, box2[:, 1] + box2[:, 3] / 2\n","\n","    # get the coordinates of the intersection rectangle\n","    inter_rect_x1 = torch.max(b1_x1.unsqueeze(1), b2_x1)\n","    inter_rect_y1 = torch.max(b1_y1.unsqueeze(1), b2_y1)\n","    inter_rect_x2 = torch.min(b1_x2.unsqueeze(1), b2_x2)\n","    inter_rect_y2 = torch.min(b1_y2.unsqueeze(1), b2_y2)\n","    # Intersection area\n","    inter_area = torch.clamp(inter_rect_x2 - inter_rect_x1, 0) * torch.clamp(inter_rect_y2 - inter_rect_y1, 0)\n","    # Union Area\n","    b1_area = ((b1_x2 - b1_x1) * (b1_y2 - b1_y1))\n","    b1_area = ((b1_x2 - b1_x1) * (b1_y2 - b1_y1)).view(-1,1).expand(N,M)\n","    b2_area = ((b2_x2 - b2_x1) * (b2_y2 - b2_y1)).view(1,-1).expand(N,M)\n","\n","    return inter_area / (b1_area + b2_area - inter_area + 1e-16)\n","\n","\n","def build_targets_max(target, anchor_wh, nA, nC, nGh, nGw):\n","    \"\"\"\n","    returns nT, nCorrect, tx, ty, tw, th, tconf, tcls\n","    \"\"\"\n","    nB = len(target)  # number of images in batch\n","\n","    txy = torch.zeros(nB, nA, nGh, nGw, 2).cuda()  # batch size, anchors, grid size\n","    twh = torch.zeros(nB, nA, nGh, nGw, 2).cuda()\n","    tconf = torch.LongTensor(nB, nA, nGh, nGw).fill_(0).cuda()\n","    tcls = torch.ByteTensor(nB, nA, nGh, nGw, nC).fill_(0).cuda()  # nC = number of classes\n","    tid = torch.LongTensor(nB, nA, nGh, nGw, 1).fill_(-1).cuda() \n","    for b in range(nB):\n","        t = target[b]\n","        t_id = t[:, 1].clone().long().cuda()\n","        t = t[:,[0,2,3,4,5]]\n","        nTb = len(t)  # number of targets\n","        if nTb == 0:\n","            continue\n","\n","        #gxy, gwh = t[:, 1:3] * nG, t[:, 3:5] * nG\n","        gxy, gwh = t[: , 1:3].clone() , t[:, 3:5].clone()\n","        gxy[:, 0] = gxy[:, 0] * nGw\n","        gxy[:, 1] = gxy[:, 1] * nGh\n","        gwh[:, 0] = gwh[:, 0] * nGw\n","        gwh[:, 1] = gwh[:, 1] * nGh\n","        gi = torch.clamp(gxy[:, 0], min=0, max=nGw -1).long()\n","        gj = torch.clamp(gxy[:, 1], min=0, max=nGh -1).long()\n","\n","        # Get grid box indices and prevent overflows (i.e. 13.01 on 13 anchors)\n","        #gi, gj = torch.clamp(gxy.long(), min=0, max=nG - 1).t()\n","        #gi, gj = gxy.long().t()\n","\n","        # iou of targets-anchors (using wh only)\n","        box1 = gwh\n","        box2 = anchor_wh.unsqueeze(1)\n","        inter_area = torch.min(box1, box2).prod(2)\n","        iou = inter_area / (box1.prod(1) + box2.prod(2) - inter_area + 1e-16)\n","\n","        # Select best iou_pred and anchor\n","        iou_best, a = iou.max(0)  # best anchor [0-2] for each target\n","\n","        # Select best unique target-anchor combinations\n","        if nTb > 1:\n","            _, iou_order = torch.sort(-iou_best)  # best to worst\n","\n","            # Unique anchor selection\n","            u = torch.stack((gi, gj, a), 0)[:, iou_order]\n","            # _, first_unique = np.unique(u, axis=1, return_index=True)  # first unique indices\n","            first_unique = return_torch_unique_index(u, torch.unique(u, dim=1))  # torch alternative\n","            i = iou_order[first_unique]\n","            # best anchor must share significant commonality (iou) with target\n","            i = i[iou_best[i] > 0.60]  # TODO: examine arbitrary threshold\n","            if len(i) == 0:\n","                continue\n","\n","            a, gj, gi, t = a[i], gj[i], gi[i], t[i]\n","            t_id = t_id[i]\n","            if len(t.shape) == 1:\n","                t = t.view(1, 5)\n","        else:\n","            if iou_best < 0.60:\n","                continue\n","        \n","        tc, gxy, gwh = t[:, 0].long(), t[:, 1:3].clone(), t[:, 3:5].clone()\n","        gxy[:, 0] = gxy[:, 0] * nGw\n","        gxy[:, 1] = gxy[:, 1] * nGh\n","        gwh[:, 0] = gwh[:, 0] * nGw\n","        gwh[:, 1] = gwh[:, 1] * nGh\n","\n","        # XY coordinates\n","        txy[b, a, gj, gi] = gxy - gxy.floor()\n","\n","        # Width and height\n","        twh[b, a, gj, gi] = torch.log(gwh / anchor_wh[a])  # yolo method\n","        # twh[b, a, gj, gi] = torch.sqrt(gwh / anchor_wh[a]) / 2 # power method\n","\n","        # One-hot encoding of label\n","        tcls[b, a, gj, gi, tc] = 1\n","        tconf[b, a, gj, gi] = 1\n","        tid[b, a, gj, gi] = t_id.unsqueeze(1)\n","    tbox = torch.cat([txy, twh], -1)\n","    return tconf, tbox, tid\n","\n","\n","\n","def build_targets_thres(target, anchor_wh, nA, nC, nGh, nGw):\n","    ID_THRESH = 0.5\n","    FG_THRESH = 0.5\n","    BG_THRESH = 0.4\n","    nB = len(target)  # number of images in batch\n","    assert(len(anchor_wh)==nA)\n","\n","    tbox = torch.zeros(nB, nA, nGh, nGw, 4).cuda()  # batch size, anchors, grid size\n","    tconf = torch.LongTensor(nB, nA, nGh, nGw).fill_(0).cuda()\n","    tid = torch.LongTensor(nB, nA, nGh, nGw, 1).fill_(-1).cuda() \n","    for b in range(nB):\n","        t = target[b]\n","        t_id = t[:, 1].clone().long().cuda()\n","        t = t[:,[0,2,3,4,5]]\n","        nTb = len(t)  # number of targets\n","        if nTb == 0:\n","            continue\n","\n","        gxy, gwh = t[: , 1:3].clone() , t[:, 3:5].clone()\n","        gxy[:, 0] = gxy[:, 0] * nGw\n","        gxy[:, 1] = gxy[:, 1] * nGh\n","        gwh[:, 0] = gwh[:, 0] * nGw\n","        gwh[:, 1] = gwh[:, 1] * nGh\n","        gxy[:, 0] = torch.clamp(gxy[:, 0], min=0, max=nGw -1)\n","        gxy[:, 1] = torch.clamp(gxy[:, 1], min=0, max=nGh -1)\n","\n","        gt_boxes = torch.cat([gxy, gwh], dim=1)                                            # Shape Ngx4 (xc, yc, w, h)\n","        \n","        anchor_mesh = generate_anchor(nGh, nGw, anchor_wh)\n","        anchor_list = anchor_mesh.permute(0,2,3,1).contiguous().view(-1, 4)              # Shpae (nA x nGh x nGw) x 4\n","        #print(anchor_list.shape, gt_boxes.shape)\n","        iou_pdist = bbox_iou(anchor_list, gt_boxes)                                      # Shape (nA x nGh x nGw) x Ng\n","        iou_max, max_gt_index = torch.max(iou_pdist, dim=1)                              # Shape (nA x nGh x nGw), both\n","\n","        iou_map = iou_max.view(nA, nGh, nGw)       \n","        gt_index_map = max_gt_index.view(nA, nGh, nGw)\n","\n","        #nms_map = pooling_nms(iou_map, 3)\n","        \n","        id_index = iou_map > ID_THRESH\n","        fg_index = iou_map > FG_THRESH                                                    \n","        bg_index = iou_map < BG_THRESH \n","        ign_index = (iou_map < FG_THRESH) * (iou_map > BG_THRESH)\n","        tconf[b][fg_index] = 1\n","        tconf[b][bg_index] = 0\n","        tconf[b][ign_index] = -1\n","\n","        gt_index = gt_index_map[fg_index]\n","        gt_box_list = gt_boxes[gt_index]\n","        gt_id_list = t_id[gt_index_map[id_index]]\n","        #print(gt_index.shape, gt_index_map[id_index].shape, gt_boxes.shape)\n","        if torch.sum(fg_index) > 0:\n","            tid[b][id_index] =  gt_id_list.unsqueeze(1)\n","            fg_anchor_list = anchor_list.view(nA, nGh, nGw, 4)[fg_index] \n","            delta_target = encode_delta(gt_box_list, fg_anchor_list)\n","            tbox[b][fg_index] = delta_target\n","    return tconf, tbox, tid\n","\n","def generate_anchor(nGh, nGw, anchor_wh):\n","    nA = len(anchor_wh)\n","    yy, xx =torch.meshgrid(torch.arange(nGh), torch.arange(nGw))\n","    xx, yy = xx.cuda(), yy.cuda()\n","\n","    mesh = torch.stack([xx, yy], dim=0)                                              # Shape 2, nGh, nGw\n","    mesh = mesh.unsqueeze(0).repeat(nA,1,1,1).float()                                # Shape nA x 2 x nGh x nGw\n","    anchor_offset_mesh = anchor_wh.unsqueeze(-1).unsqueeze(-1).repeat(1, 1, nGh,nGw) # Shape nA x 2 x nGh x nGw\n","    anchor_mesh = torch.cat([mesh, anchor_offset_mesh], dim=1)                       # Shape nA x 4 x nGh x nGw\n","    return anchor_mesh\n","\n","def encode_delta(gt_box_list, fg_anchor_list):\n","    px, py, pw, ph = fg_anchor_list[:, 0], fg_anchor_list[:,1], \\\n","                     fg_anchor_list[:, 2], fg_anchor_list[:,3]\n","    gx, gy, gw, gh = gt_box_list[:, 0], gt_box_list[:, 1], \\\n","                     gt_box_list[:, 2], gt_box_list[:, 3]\n","    dx = (gx - px) / pw\n","    dy = (gy - py) / ph\n","    dw = torch.log(gw/pw)\n","    dh = torch.log(gh/ph)\n","    return torch.stack([dx, dy, dw, dh], dim=1)\n","\n","def decode_delta(delta, fg_anchor_list):\n","    px, py, pw, ph = fg_anchor_list[:, 0], fg_anchor_list[:,1], \\\n","                     fg_anchor_list[:, 2], fg_anchor_list[:,3]\n","    dx, dy, dw, dh = delta[:, 0], delta[:, 1], delta[:, 2], delta[:, 3]\n","    gx = pw * dx + px\n","    gy = ph * dy + py\n","    gw = pw * torch.exp(dw)\n","    gh = ph * torch.exp(dh)\n","    return torch.stack([gx, gy, gw, gh], dim=1)\n","\n","def decode_delta_map(delta_map, anchors):\n","    '''\n","    :param: delta_map, shape (nB, nA, nGh, nGw, 4)\n","    :param: anchors, shape (nA,4)\n","    '''\n","    nB, nA, nGh, nGw, _ = delta_map.shape\n","    anchor_mesh = generate_anchor(nGh, nGw, anchors) \n","    anchor_mesh = anchor_mesh.permute(0,2,3,1).contiguous()              # Shpae (nA x nGh x nGw) x 4\n","    anchor_mesh = anchor_mesh.unsqueeze(0).repeat(nB,1,1,1,1)\n","    pred_list = decode_delta(delta_map.view(-1,4), anchor_mesh.view(-1,4))\n","    pred_map = pred_list.view(nB, nA, nGh, nGw, 4)\n","    return pred_map\n","\n","\n","def pooling_nms(heatmap, kernel=1):\n","    pad = (kernel -1 ) // 2\n","    hmax = F.max_pool2d(heatmap, (kernel, kernel), stride=1, padding=pad)\n","    keep = (hmax == heatmap).float()\n","    return keep * heatmap\n","\n","def non_max_suppression(prediction, conf_thres=0.5, nms_thres=0.4, method='standard'):\n","    \"\"\"\n","    Removes detections with lower object confidence score than 'conf_thres'\n","    Non-Maximum Suppression to further filter detections.\n","    Returns detections with shape:\n","        (x1, y1, x2, y2, object_conf, class_score, class_pred)\n","    Args:\n","        prediction,\n","        conf_thres,\n","        nms_thres,\n","        method = 'standard' or 'fast'\n","    \"\"\"\n","\n","    output = [None for _ in range(len(prediction))]\n","    for image_i, pred in enumerate(prediction):\n","        # Filter out confidence scores below threshold\n","        # Get score and class with highest confidence\n","\n","        v = pred[:, 4] > conf_thres\n","        v = v.nonzero().squeeze()\n","        if len(v.shape) == 0:\n","            v = v.unsqueeze(0)\n","\n","        pred = pred[v]\n","\n","        # If none are remaining => process next image\n","        nP = pred.shape[0]\n","        if not nP:\n","            continue\n","        # From (center x, center y, width, height) to (x1, y1, x2, y2)\n","        pred[:, :4] = xywh2xyxy(pred[:, :4])\n","\n","        \n","        # Non-maximum suppression\n","        if method == 'standard':\n","            nms_indices = nms(pred[:, :4], pred[:, 4], nms_thres)\n","        elif method == 'fast':\n","            nms_indices = fast_nms(pred[:, :4], pred[:, 4], iou_thres=nms_thres, conf_thres=conf_thres)\n","        else:\n","            raise ValueError('Invalid NMS type!')\n","        det_max = pred[nms_indices]        \n","\n","        if len(det_max) > 0:\n","            # Add max detections to outputs\n","            output[image_i] = det_max if output[image_i] is None else torch.cat((output[image_i], det_max))\n","\n","    return output\n","\n","def fast_nms(boxes, scores, iou_thres:float=0.5, top_k:int=200, second_threshold:bool=False, conf_thres:float=0.5):\n","    '''\n","    Vectorized, approximated, fast NMS, adopted from YOLACT:\n","    https://github.com/dbolya/yolact/blob/master/layers/functions/detection.py\n","    The original version is for multi-class NMS, here we simplify the code for single-class NMS\n","    '''\n","    scores, idx = scores.sort(0, descending=True)\n","    \n","    idx = idx[:top_k].contiguous()\n","    scores = scores[:top_k]\n","    num_dets = idx.size()\n","\n","    boxes = boxes[idx, :]\n","\n","    iou = jaccard(boxes, boxes)\n","    iou.triu_(diagonal=1)\n","    iou_max, _ = iou.max(dim=0)\n","\n","    keep = (iou_max <= iou_thres)\n","\n","    if second_threshold:\n","        keep *= (scores > self.conf_thresh)\n","\n","    return idx[keep]\n","\n","\n","\n","@torch.jit.script\n","def intersect(box_a, box_b):\n","    \"\"\" We resize both tensors to [A,B,2] without new malloc:\n","    [A,2] -> [A,1,2] -> [A,B,2]\n","    [B,2] -> [1,B,2] -> [A,B,2]\n","    Then we compute the area of intersect between box_a and box_b.\n","    Args:\n","      box_a: (tensor) bounding boxes, Shape: [n,A,4].\n","      box_b: (tensor) bounding boxes, Shape: [n,B,4].\n","    Return:\n","      (tensor) intersection area, Shape: [n,A,B].\n","    \"\"\"\n","    n = box_a.size(0)\n","    A = box_a.size(1)\n","    B = box_b.size(1)\n","    max_xy = torch.min(box_a[:, :, 2:].unsqueeze(2).expand(n, A, B, 2),\n","                       box_b[:, :, 2:].unsqueeze(1).expand(n, A, B, 2))\n","    min_xy = torch.max(box_a[:, :, :2].unsqueeze(2).expand(n, A, B, 2),\n","                       box_b[:, :, :2].unsqueeze(1).expand(n, A, B, 2))\n","    inter = torch.clamp((max_xy - min_xy), min=0)\n","    return inter[:, :, :, 0] * inter[:, :, :, 1]\n","\n","\n","\n","def jaccard(box_a, box_b, iscrowd:bool=False):\n","    \"\"\"Compute the jaccard overlap of two sets of boxes.  The jaccard overlap\n","    is simply the intersection over union of two boxes.  Here we operate on\n","    ground truth boxes and default boxes. If iscrowd=True, put the crowd in box_b.\n","    E.g.:\n","        A ∩ B / A ∪ B = A ∩ B / (area(A) + area(B) - A ∩ B)\n","    Args:\n","        box_a: (tensor) Ground truth bounding boxes, Shape: [num_objects,4]\n","        box_b: (tensor) Prior boxes from priorbox layers, Shape: [num_priors,4]\n","    Return:\n","        jaccard overlap: (tensor) Shape: [box_a.size(0), box_b.size(0)]\n","    \"\"\"\n","    use_batch = True\n","    if box_a.dim() == 2:\n","        use_batch = False\n","        box_a = box_a[None, ...]\n","        box_b = box_b[None, ...]\n","\n","    inter = intersect(box_a, box_b)\n","    area_a = ((box_a[:, :, 2]-box_a[:, :, 0]) *\n","              (box_a[:, :, 3]-box_a[:, :, 1])).unsqueeze(2).expand_as(inter)  # [A,B]\n","    area_b = ((box_b[:, :, 2]-box_b[:, :, 0]) *\n","              (box_b[:, :, 3]-box_b[:, :, 1])).unsqueeze(1).expand_as(inter)  # [A,B]\n","    union = area_a + area_b - inter\n","\n","    out = inter / area_a if iscrowd else inter / union\n","    return out if use_batch else out.squeeze(0)\n","\n","\n","def return_torch_unique_index(u, uv):\n","    n = uv.shape[1]  # number of columns\n","    first_unique = torch.zeros(n, device=u.device).long()\n","    for j in range(n):\n","        first_unique[j] = (uv[:, j:j + 1] == u).all(0).nonzero()[0]\n","\n","    return first_unique\n","\n","\n","def strip_optimizer_from_checkpoint(filename='weights/best.pt'):\n","    # Strip optimizer from *.pt files for lighter files (reduced by 2/3 size)\n","    a = torch.load(filename, map_location='cpu')\n","    a['optimizer'] = []\n","    torch.save(a, filename.replace('.pt', '_lite.pt'))\n","\n","\n","def plot_results():\n","    \"\"\"\n","    Plot YOLO training results from the file 'results.txt'\n","    Example of what this is trying to plot can be found at: \n","    https://user-images.githubusercontent.com/26833433/63258271-fe9d5300-c27b-11e9-9a15-95038daf4438.png\n","    An example results.txt file:\n","    import os; os.system('wget https://storage.googleapis.com/ultralytics/yolov3/results_v1.txt')\n","    \"\"\"\n","    plt.figure(figsize=(14, 7))\n","    s = ['X + Y', 'Width + Height', 'Confidence', 'Classification', 'Total Loss', 'mAP', 'Recall', 'Precision']\n","    files = sorted(glob.glob('results*.txt'))\n","    for f in files:\n","        results = np.loadtxt(f, usecols=[2, 3, 4, 5, 6, 9, 10, 11]).T  # column 11 is mAP\n","        x = range(1, results.shape[1])\n","        for i in range(8):\n","            plt.subplot(2, 4, i + 1)\n","            plt.plot(x, results[i, x], marker='.', label=f)\n","            plt.title(s[i])\n","            if i == 0:\n","                plt.legend()"],"outputs":[],"metadata":{}}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":4}}