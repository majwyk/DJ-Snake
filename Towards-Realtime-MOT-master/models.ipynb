{"cells":[{"cell_type":"code","execution_count":1,"source":["import os\n","from collections import defaultdict,OrderedDict\n","\n","import torch.nn as nn\n","\n","from utils.parse_config import *\n","from utils.utils import *\n","import time\n","import math\n","\n","try:\n","    from utils.syncbn import SyncBN\n","    batch_norm=SyncBN #nn.BatchNorm2d\n","except ImportError:\n","    batch_norm=nn.BatchNorm2d\n","\n","def create_modules(module_defs):\n","    \"\"\"\n","    Constructs module list of layer blocks from module configuration in module_defs\n","    \"\"\"\n","    hyperparams = module_defs.pop(0)\n","    output_filters = [int(hyperparams['channels'])]\n","    module_list = nn.ModuleList()\n","    yolo_layer_count = 0\n","    for i, module_def in enumerate(module_defs):\n","        modules = nn.Sequential()\n","\n","        if module_def['type'] == 'convolutional':\n","            bn = int(module_def['batch_normalize'])\n","            filters = int(module_def['filters'])\n","            kernel_size = int(module_def['size'])\n","            pad = (kernel_size - 1) // 2 if int(module_def['pad']) else 0\n","            modules.add_module('conv_%d' % i, nn.Conv2d(in_channels=output_filters[-1],\n","                                                        out_channels=filters,\n","                                                        kernel_size=kernel_size,\n","                                                        stride=int(module_def['stride']),\n","                                                        padding=pad,\n","                                                        bias=not bn))\n","            if bn:\n","                after_bn = batch_norm(filters)\n","                modules.add_module('batch_norm_%d' % i, after_bn)\n","                # BN is uniformly initialized by default in pytorch 1.0.1. \n","                # In pytorch>1.2.0, BN weights are initialized with constant 1,\n","                # but we find with the uniform initialization the model converges faster.\n","                nn.init.uniform_(after_bn.weight) \n","                nn.init.zeros_(after_bn.bias)\n","            if module_def['activation'] == 'leaky':\n","                modules.add_module('leaky_%d' % i, nn.LeakyReLU(0.1))\n","\n","        elif module_def['type'] == 'maxpool':\n","            kernel_size = int(module_def['size'])\n","            stride = int(module_def['stride'])\n","            if kernel_size == 2 and stride == 1:\n","                modules.add_module('_debug_padding_%d' % i, nn.ZeroPad2d((0, 1, 0, 1)))\n","            maxpool = nn.MaxPool2d(kernel_size=kernel_size, stride=stride, padding=int((kernel_size - 1) // 2))\n","            modules.add_module('maxpool_%d' % i, maxpool)\n","\n","        elif module_def['type'] == 'upsample':\n","            upsample = Upsample(scale_factor=int(module_def['stride']))\n","            modules.add_module('upsample_%d' % i, upsample)\n","\n","        elif module_def['type'] == 'route':\n","            layers = [int(x) for x in module_def['layers'].split(',')]\n","            filters = sum([output_filters[i + 1 if i > 0 else i] for i in layers])\n","            modules.add_module('route_%d' % i, EmptyLayer())\n","\n","        elif module_def['type'] == 'shortcut':\n","            filters = output_filters[int(module_def['from'])]\n","            modules.add_module('shortcut_%d' % i, EmptyLayer())\n","\n","        elif module_def['type'] == 'yolo':\n","            anchor_idxs = [int(x) for x in module_def['mask'].split(',')]\n","            # Extract anchors\n","            anchors = [float(x) for x in module_def['anchors'].split(',')]\n","            anchors = [(anchors[i], anchors[i + 1]) for i in range(0, len(anchors), 2)]\n","            anchors = [anchors[i] for i in anchor_idxs]\n","            nC = int(module_def['classes'])  # number of classes\n","            img_size = (int(hyperparams['width']),int(hyperparams['height']))\n","            # Define detection layer\n","            yolo_layer = YOLOLayer(anchors, nC, int(hyperparams['nID']), \n","                                   int(hyperparams['embedding_dim']), img_size, yolo_layer_count)\n","            modules.add_module('yolo_%d' % i, yolo_layer)\n","            yolo_layer_count += 1\n","\n","        # Register module list and number of output filters\n","        module_list.append(modules)\n","        output_filters.append(filters)\n","\n","    return hyperparams, module_list\n","\n","\n","class EmptyLayer(nn.Module):\n","    \"\"\"Placeholder for 'route' and 'shortcut' layers\"\"\"\n","\n","    def __init__(self):\n","        super(EmptyLayer, self).__init__()\n","\n","    def forward(self, x):\n","        return x\n","\n","\n","class Upsample(nn.Module):\n","    # Custom Upsample layer (nn.Upsample gives deprecated warning message)\n","\n","    def __init__(self, scale_factor=1, mode='nearest'):\n","        super(Upsample, self).__init__()\n","        self.scale_factor = scale_factor\n","        self.mode = mode\n","\n","    def forward(self, x):\n","        return F.interpolate(x, scale_factor=self.scale_factor, mode=self.mode)\n","\n","\n","class YOLOLayer(nn.Module):\n","    def __init__(self, anchors, nC, nID, nE, img_size, yolo_layer):\n","        super(YOLOLayer, self).__init__()\n","        self.layer = yolo_layer\n","        nA = len(anchors)\n","        self.anchors = torch.FloatTensor(anchors)\n","        self.nA = nA  # number of anchors (3)\n","        self.nC = nC  # number of classes (80)\n","        self.nID = nID # number of identities\n","        self.img_size = 0\n","        self.emb_dim = nE \n","        self.shift = [1, 3, 5]\n","\n","        self.SmoothL1Loss  = nn.SmoothL1Loss()\n","        self.SoftmaxLoss = nn.CrossEntropyLoss(ignore_index=-1)\n","        self.CrossEntropyLoss = nn.CrossEntropyLoss()\n","        self.IDLoss = nn.CrossEntropyLoss(ignore_index=-1)\n","        self.s_c = nn.Parameter(-4.15*torch.ones(1))  # -4.15\n","        self.s_r = nn.Parameter(-4.85*torch.ones(1))  # -4.85\n","        self.s_id = nn.Parameter(-2.3*torch.ones(1))  # -2.3\n","        \n","        self.emb_scale = math.sqrt(2) * math.log(self.nID-1) if self.nID>1 else 1\n","\n","        \n","\n","    def forward(self, p_cat,  img_size, targets=None, classifier=None, test_emb=False):\n","        p, p_emb = p_cat[:, :24, ...], p_cat[:, 24:, ...]\n","        nB, nGh, nGw = p.shape[0], p.shape[-2], p.shape[-1]\n","\n","        if self.img_size != img_size:\n","            create_grids(self, img_size, nGh, nGw)\n","\n","            if p.is_cuda:\n","                self.grid_xy = self.grid_xy.cuda()\n","                self.anchor_wh = self.anchor_wh.cuda()\n","\n","        p = p.view(nB, self.nA, self.nC + 5, nGh, nGw).permute(0, 1, 3, 4, 2).contiguous()  # prediction\n","        \n","        p_emb = p_emb.permute(0,2,3,1).contiguous()\n","        p_box = p[..., :4]\n","        p_conf = p[..., 4:6].permute(0, 4, 1, 2, 3)  # Conf\n","\n","        # Training\n","        if targets is not None:\n","            if test_emb:\n","                tconf, tbox, tids = build_targets_max(targets, self.anchor_vec.cuda(), self.nA, self.nC, nGh, nGw)\n","            else:\n","                tconf, tbox, tids = build_targets_thres(targets, self.anchor_vec.cuda(), self.nA, self.nC, nGh, nGw)\n","            tconf, tbox, tids = tconf.cuda(), tbox.cuda(), tids.cuda()\n","            mask = tconf > 0\n","\n","            # Compute losses\n","            nT = sum([len(x) for x in targets])  # number of targets\n","            nM = mask.sum().float()  # number of anchors (assigned to targets)\n","            nP = torch.ones_like(mask).sum().float()\n","            if nM > 0:\n","                lbox = self.SmoothL1Loss(p_box[mask], tbox[mask])\n","            else:\n","                FT = torch.cuda.FloatTensor if p_conf.is_cuda else torch.FloatTensor\n","                lbox, lconf =  FT([0]), FT([0])\n","            lconf =  self.SoftmaxLoss(p_conf, tconf)\n","            lid = torch.Tensor(1).fill_(0).squeeze().cuda()\n","            emb_mask,_ = mask.max(1)\n","            \n","            # For convenience we use max(1) to decide the id, TODO: more reseanable strategy\n","            tids,_ = tids.max(1) \n","            tids = tids[emb_mask]\n","            embedding = p_emb[emb_mask].contiguous()\n","            embedding = self.emb_scale * F.normalize(embedding)\n","            nI = emb_mask.sum().float()\n","            \n","            if  test_emb:\n","                if np.prod(embedding.shape)==0  or np.prod(tids.shape) == 0:\n","                    return torch.zeros(0, self.emb_dim+1).cuda()\n","                emb_and_gt = torch.cat([embedding, tids.float()], dim=1)\n","                return emb_and_gt\n","            \n","            if len(embedding) > 1:\n","                logits = classifier(embedding).contiguous()\n","                lid =  self.IDLoss(logits, tids.squeeze())\n","\n","            # Sum loss components\n","            loss = torch.exp(-self.s_r)*lbox + torch.exp(-self.s_c)*lconf + torch.exp(-self.s_id)*lid + \\\n","                   (self.s_r + self.s_c + self.s_id)\n","            loss *= 0.5\n","\n","            return loss, loss.item(), lbox.item(), lconf.item(), lid.item(), nT\n","\n","        else:\n","            p_conf = torch.softmax(p_conf, dim=1)[:,1,...].unsqueeze(-1)\n","            p_emb = F.normalize(p_emb.unsqueeze(1).repeat(1,self.nA,1,1,1).contiguous(), dim=-1)\n","            #p_emb_up = F.normalize(shift_tensor_vertically(p_emb, -self.shift[self.layer]), dim=-1)\n","            #p_emb_down = F.normalize(shift_tensor_vertically(p_emb, self.shift[self.layer]), dim=-1)\n","            p_cls = torch.zeros(nB,self.nA,nGh,nGw,1).cuda()               # Temp\n","            p = torch.cat([p_box, p_conf, p_cls, p_emb], dim=-1)\n","            #p = torch.cat([p_box, p_conf, p_cls, p_emb, p_emb_up, p_emb_down], dim=-1)\n","            p[..., :4] = decode_delta_map(p[..., :4], self.anchor_vec.to(p))\n","            p[..., :4] *= self.stride\n","\n","            return p.view(nB, -1, p.shape[-1])\n","\n","\n","class Darknet(nn.Module):\n","    \"\"\"YOLOv3 object detection model\"\"\"\n","\n","    def __init__(self, cfg_dict, nID=0, test_emb=False):\n","        super(Darknet, self).__init__()\n","        if isinstance(cfg_dict, str):\n","            cfg_dict = parse_model_cfg(cfg_dict)\n","        self.module_defs = cfg_dict \n","        self.module_defs[0]['nID'] = nID\n","        self.img_size = [int(self.module_defs[0]['width']), int(self.module_defs[0]['height'])]\n","        self.emb_dim = int(self.module_defs[0]['embedding_dim'])\n","        self.hyperparams, self.module_list = create_modules(self.module_defs)\n","        self.loss_names = ['loss', 'box', 'conf', 'id', 'nT']\n","        self.losses = OrderedDict()\n","        for ln in self.loss_names:\n","            self.losses[ln] = 0\n","        self.test_emb = test_emb\n","        \n","        self.classifier = nn.Linear(self.emb_dim, nID) if nID>0 else None\n","\n","\n","\n","    def forward(self, x, targets=None, targets_len=None):\n","        self.losses = OrderedDict()\n","        for ln in self.loss_names:\n","            self.losses[ln] = 0\n","        is_training = (targets is not None) and (not self.test_emb)\n","        #img_size = x.shape[-1]\n","        layer_outputs = []\n","        output = []\n","\n","        for i, (module_def, module) in enumerate(zip(self.module_defs, self.module_list)):\n","            mtype = module_def['type']\n","            if mtype in ['convolutional', 'upsample', 'maxpool']:\n","                x = module(x)\n","            elif mtype == 'route':\n","                layer_i = [int(x) for x in module_def['layers'].split(',')]\n","                if len(layer_i) == 1:\n","                    x = layer_outputs[layer_i[0]]\n","                else:\n","                    x = torch.cat([layer_outputs[i] for i in layer_i], 1)\n","            elif mtype == 'shortcut':\n","                layer_i = int(module_def['from'])\n","                x = layer_outputs[-1] + layer_outputs[layer_i]\n","            elif mtype == 'yolo':\n","                if is_training:  # get loss\n","                    targets = [targets[i][:int(l)] for i,l in enumerate(targets_len)]\n","                    x, *losses = module[0](x, self.img_size, targets, self.classifier)\n","                    for name, loss in zip(self.loss_names, losses):\n","                        self.losses[name] += loss\n","                elif self.test_emb:\n","                    if targets is not None:\n","                        targets = [targets[i][:int(l)] for i,l in enumerate(targets_len)]\n","                    x = module[0](x, self.img_size, targets, self.classifier, self.test_emb)\n","                else:  # get detections\n","                    x = module[0](x, self.img_size)\n","                output.append(x)\n","            layer_outputs.append(x)\n","\n","        if is_training:\n","            self.losses['nT'] /= 3 \n","            output = [o.squeeze() for o in output]\n","            return sum(output), torch.Tensor(list(self.losses.values())).cuda()\n","        elif self.test_emb:\n","            return torch.cat(output, 0)\n","        return torch.cat(output, 1)\n","\n","def shift_tensor_vertically(t, delta):\n","    # t should be a 5-D tensor (nB, nA, nH, nW, nC)\n","    res = torch.zeros_like(t)\n","    if delta >= 0:\n","        res[:,:, :-delta, :, :] = t[:,:, delta:, :, :]\n","    else:\n","        res[:,:, -delta:, :, :] = t[:,:, :delta, :, :]\n","    return res \n","\n","def create_grids(self, img_size, nGh, nGw):\n","    self.stride = img_size[0]/nGw\n","    assert self.stride == img_size[1] / nGh, \\\n","            \"{} v.s. {}/{}\".format(self.stride, img_size[1], nGh)\n","\n","    # build xy offsets\n","    grid_x = torch.arange(nGw).repeat((nGh, 1)).view((1, 1, nGh, nGw)).float()\n","    grid_y = torch.arange(nGh).repeat((nGw, 1)).transpose(0,1).view((1, 1, nGh, nGw)).float()\n","    #grid_y = grid_x.permute(0, 1, 3, 2)\n","    self.grid_xy = torch.stack((grid_x, grid_y), 4)\n","\n","    # build wh gains\n","    self.anchor_vec = self.anchors / self.stride\n","    self.anchor_wh = self.anchor_vec.view(1, self.nA, 1, 1, 2)\n","\n","\n","def load_darknet_weights(self, weights, cutoff=-1):\n","    # Parses and loads the weights stored in 'weights'\n","    # cutoff: save layers between 0 and cutoff (if cutoff = -1 all are saved)\n","    weights_file = weights.split('/')[-1]\n","\n","    # Try to download weights if not available locally\n","    if not os.path.isfile(weights):\n","        try:\n","            os.system('wget https://pjreddie.com/media/files/' + weights_file + ' -O ' + weights)\n","        except IOError:\n","            print(weights + ' not found')\n","\n","    # Establish cutoffs\n","    if weights_file == 'darknet53.conv.74':\n","        cutoff = 75\n","    elif weights_file == 'yolov3-tiny.conv.15':\n","        cutoff = 15\n","\n","    # Open the weights file\n","    fp = open(weights, 'rb')\n","    header = np.fromfile(fp, dtype=np.int32, count=5)  # First five are header values\n","\n","    # Needed to write header when saving weights\n","    self.header_info = header\n","\n","    self.seen = header[3]  # number of images seen during training\n","    weights = np.fromfile(fp, dtype=np.float32)  # The rest are weights\n","    fp.close()\n","\n","    ptr = 0\n","    for i, (module_def, module) in enumerate(zip(self.module_defs[:cutoff], self.module_list[:cutoff])):\n","        if module_def['type'] == 'convolutional':\n","            conv_layer = module[0]\n","            if module_def['batch_normalize']:\n","                # Load BN bias, weights, running mean and running variance\n","                bn_layer = module[1]\n","                num_b = bn_layer.bias.numel()  # Number of biases\n","                # Bias\n","                bn_b = torch.from_numpy(weights[ptr:ptr + num_b]).view_as(bn_layer.bias)\n","                bn_layer.bias.data.copy_(bn_b)\n","                ptr += num_b\n","                # Weight\n","                bn_w = torch.from_numpy(weights[ptr:ptr + num_b]).view_as(bn_layer.weight)\n","                bn_layer.weight.data.copy_(bn_w)\n","                ptr += num_b\n","                # Running Mean\n","                bn_rm = torch.from_numpy(weights[ptr:ptr + num_b]).view_as(bn_layer.running_mean)\n","                bn_layer.running_mean.data.copy_(bn_rm)\n","                ptr += num_b\n","                # Running Var\n","                bn_rv = torch.from_numpy(weights[ptr:ptr + num_b]).view_as(bn_layer.running_var)\n","                bn_layer.running_var.data.copy_(bn_rv)\n","                ptr += num_b\n","            else:\n","                # Load conv. bias\n","                num_b = conv_layer.bias.numel()\n","                conv_b = torch.from_numpy(weights[ptr:ptr + num_b]).view_as(conv_layer.bias)\n","                conv_layer.bias.data.copy_(conv_b)\n","                ptr += num_b\n","            # Load conv. weights\n","            num_w = conv_layer.weight.numel()\n","            conv_w = torch.from_numpy(weights[ptr:ptr + num_w]).view_as(conv_layer.weight)\n","            conv_layer.weight.data.copy_(conv_w)\n","            ptr += num_w\n","\n","\n","\"\"\"\n","    @:param path    - path of the new weights file\n","    @:param cutoff  - save layers between 0 and cutoff (cutoff = -1 -> all are saved)\n","\"\"\"\n","\n","\n","def save_weights(self, path, cutoff=-1):\n","    fp = open(path, 'wb')\n","    self.header_info[3] = self.seen  # number of images seen during training\n","    self.header_info.tofile(fp)\n","\n","    # Iterate through layers\n","    for i, (module_def, module) in enumerate(zip(self.module_defs[:cutoff], self.module_list[:cutoff])):\n","        if module_def['type'] == 'convolutional':\n","            conv_layer = module[0]\n","            # If batch norm, load bn first\n","            if module_def['batch_normalize']:\n","                bn_layer = module[1]\n","                bn_layer.bias.data.cpu().numpy().tofile(fp)\n","                bn_layer.weight.data.cpu().numpy().tofile(fp)\n","                bn_layer.running_mean.data.cpu().numpy().tofile(fp)\n","                bn_layer.running_var.data.cpu().numpy().tofile(fp)\n","            # Load conv bias\n","            else:\n","                conv_layer.bias.data.cpu().numpy().tofile(fp)\n","            # Load conv weights\n","            conv_layer.weight.data.cpu().numpy().tofile(fp)\n","\n","    fp.close()"],"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'torch'","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[1;32mf:\\学习所用\\2021年下半年\\计算机视觉\\期末作业\\Towards-Realtime-MOT-master\\models.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='file://f:\\学习所用\\2021年下半年\\计算机视觉\\期末作业\\Towards-Realtime-MOT-master\\models.py?line=2'>3</a>\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mOrderedDict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      <a href='file://f:\\学习所用\\2021年下半年\\计算机视觉\\期末作业\\Towards-Realtime-MOT-master\\models.py?line=3'>4</a>\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> <a href='file://f:\\学习所用\\2021年下半年\\计算机视觉\\期末作业\\Towards-Realtime-MOT-master\\models.py?line=4'>5</a>\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      <a href='file://f:\\学习所用\\2021年下半年\\计算机视觉\\期末作业\\Towards-Realtime-MOT-master\\models.py?line=5'>6</a>\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      <a href='file://f:\\学习所用\\2021年下半年\\计算机视觉\\期末作业\\Towards-Realtime-MOT-master\\models.py?line=6'>7</a>\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_config\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"]}],"metadata":{}}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":4}}